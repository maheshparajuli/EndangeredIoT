#model is quantized using int8